# MarchProxy Unified NLB Architecture - Docker Compose
# Version: v1.0.0
# Architecture: NLB (L3/L4) + ALB (L7) + DBLB + AILB + RTMP modules

version: '3.8'

services:
  # ============================================================================
  # Infrastructure Services
  # ============================================================================

  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: marchproxy-postgres
    environment:
      POSTGRES_DB: marchproxy
      POSTGRES_USER: marchproxy
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-marchproxy123}
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    networks:
      - marchproxy-internal
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U marchproxy"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: marchproxy-redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-redis123}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - marchproxy-internal
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # ============================================================================
  # Kong API Gateway (APILB)
  # ============================================================================

  # Kong Database (separate from main marchproxy database) - PERFORMANCE OPTIMIZED
  kong-db:
    image: postgres:16-alpine
    container_name: marchproxy-kong-db
    environment:
      POSTGRES_USER: kong
      POSTGRES_PASSWORD: ${KONG_DB_PASSWORD:-kongpass}
      POSTGRES_DB: kong
      # Performance tuning for Kong workload
      POSTGRES_INITDB_ARGS: "--data-checksums"
    command:
      - "postgres"
      # Connection settings
      - "-c"
      - "max_connections=500"
      - "-c"
      - "superuser_reserved_connections=3"
      # Memory settings (tune based on available RAM)
      - "-c"
      - "shared_buffers=256MB"
      - "-c"
      - "effective_cache_size=768MB"
      - "-c"
      - "work_mem=16MB"
      - "-c"
      - "maintenance_work_mem=128MB"
      # WAL settings for write performance
      - "-c"
      - "wal_buffers=16MB"
      - "-c"
      - "checkpoint_completion_target=0.9"
      - "-c"
      - "max_wal_size=1GB"
      - "-c"
      - "min_wal_size=100MB"
      # Query optimization
      - "-c"
      - "random_page_cost=1.1"
      - "-c"
      - "effective_io_concurrency=200"
      # Parallel query execution
      - "-c"
      - "max_parallel_workers_per_gather=2"
      - "-c"
      - "max_parallel_workers=4"
      # Logging (minimal for performance)
      - "-c"
      - "logging_collector=off"
      - "-c"
      - "log_statement=none"
      # Disable fsync for dev (ENABLE IN PRODUCTION!)
      # - "-c"
      # - "fsync=off"
    volumes:
      - kong_db_data:/var/lib/postgresql/data
    networks:
      - marchproxy-internal
    # Shared memory for PostgreSQL
    shm_size: 256mb
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U kong"]
      interval: 10s
      timeout: 5s
      retries: 5
    labels:
      - "service=marchproxy-kong-db"
      - "component=database"
      - "performance=optimized"

  # Kong Database Migrations (runs once on startup)
  kong-migrations:
    image: kong:3.9
    container_name: marchproxy-kong-migrations
    command: kong migrations bootstrap
    depends_on:
      kong-db:
        condition: service_healthy
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: kong-db
      KONG_PG_USER: kong
      KONG_PG_PASSWORD: ${KONG_DB_PASSWORD:-kongpass}
    networks:
      - marchproxy-internal
    restart: on-failure
    labels:
      - "service=marchproxy-kong-migrations"
      - "component=database"

  # Kong API Gateway - PERFORMANCE OPTIMIZED
  kong:
    image: kong:3.9
    container_name: marchproxy-kong
    depends_on:
      kong-migrations:
        condition: service_completed_successfully
    environment:
      # Database connection with connection pooling
      KONG_DATABASE: postgres
      KONG_PG_HOST: kong-db
      KONG_PG_USER: kong
      KONG_PG_PASSWORD: ${KONG_DB_PASSWORD:-kongpass}
      KONG_PG_POOL_SIZE: ${KONG_PG_POOL_SIZE:-256}
      KONG_PG_BACKLOG: ${KONG_PG_BACKLOG:-16384}
      KONG_PG_KEEPALIVE_TIMEOUT: ${KONG_PG_KEEPALIVE_TIMEOUT:-60000}

      # ============================================================
      # NGINX WORKER PERFORMANCE TUNING
      # ============================================================
      # Auto-detect CPU cores for worker processes
      KONG_NGINX_WORKER_PROCESSES: ${KONG_WORKER_PROCESSES:-auto}
      # Maximum concurrent connections per worker (default 16384)
      KONG_NGINX_MAIN_WORKER_RLIMIT_NOFILE: ${KONG_WORKER_RLIMIT_NOFILE:-1048576}
      KONG_NGINX_EVENTS_WORKER_CONNECTIONS: ${KONG_WORKER_CONNECTIONS:-65535}
      # Use epoll for Linux (most efficient)
      KONG_NGINX_EVENTS_USE: epoll
      # Accept multiple connections per worker wakeup
      KONG_NGINX_EVENTS_MULTI_ACCEPT: "on"

      # ============================================================
      # PROXY PERFORMANCE TUNING
      # ============================================================
      # Upstream keepalive connections (connection pooling)
      KONG_UPSTREAM_KEEPALIVE_POOL_SIZE: ${KONG_UPSTREAM_KEEPALIVE:-512}
      KONG_UPSTREAM_KEEPALIVE_MAX_REQUESTS: ${KONG_UPSTREAM_KEEPALIVE_REQUESTS:-10000}
      KONG_UPSTREAM_KEEPALIVE_IDLE_TIMEOUT: ${KONG_UPSTREAM_KEEPALIVE_TIMEOUT:-60}

      # Client body/header buffers for large requests
      KONG_NGINX_PROXY_CLIENT_BODY_BUFFER_SIZE: ${KONG_CLIENT_BODY_BUFFER:-128k}
      KONG_NGINX_PROXY_CLIENT_MAX_BODY_SIZE: ${KONG_CLIENT_MAX_BODY:-100m}
      KONG_NGINX_PROXY_LARGE_CLIENT_HEADER_BUFFERS: "4 32k"

      # Proxy buffering for better throughput
      KONG_NGINX_PROXY_PROXY_BUFFERING: "on"
      KONG_NGINX_PROXY_PROXY_BUFFER_SIZE: ${KONG_PROXY_BUFFER_SIZE:-128k}
      KONG_NGINX_PROXY_PROXY_BUFFERS: "4 256k"
      KONG_NGINX_PROXY_PROXY_BUSY_BUFFERS_SIZE: ${KONG_PROXY_BUSY_BUFFERS:-256k}

      # ============================================================
      # TCP OPTIMIZATION
      # ============================================================
      # Enable TCP nodelay (disable Nagle's algorithm for low latency)
      KONG_NGINX_PROXY_PROXY_SOCKET_KEEPALIVE: "on"

      # ============================================================
      # SSL/TLS PERFORMANCE
      # ============================================================
      # SSL session caching for reduced handshake overhead
      KONG_SSL_SESSION_CACHE_SIZE: ${KONG_SSL_CACHE_SIZE:-10m}
      KONG_SSL_SESSION_TIMEOUT: ${KONG_SSL_SESSION_TIMEOUT:-1d}
      # Prefer server cipher order for security + performance
      KONG_SSL_PREFER_SERVER_CIPHERS: "on"
      # Modern TLS only (faster ciphers)
      KONG_SSL_PROTOCOLS: "TLSv1.2 TLSv1.3"
      KONG_SSL_CIPHERS: "ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305"

      # ============================================================
      # DNS OPTIMIZATION
      # ============================================================
      # Faster DNS resolution with caching
      KONG_DNS_ORDER: "LAST,A,SRV,CNAME"
      KONG_DNS_STALE_TTL: ${KONG_DNS_STALE_TTL:-4}
      KONG_DNS_NOT_FOUND_TTL: ${KONG_DNS_NOT_FOUND_TTL:-1}
      KONG_DNS_ERROR_TTL: ${KONG_DNS_ERROR_TTL:-1}
      KONG_DNS_NO_SYNC: "on"

      # ============================================================
      # CACHING
      # ============================================================
      # Database cache (reduce DB roundtrips)
      KONG_DB_CACHE_TTL: ${KONG_DB_CACHE_TTL:-0}
      KONG_DB_CACHE_NEG_TTL: ${KONG_DB_CACHE_NEG_TTL:-0}
      KONG_DB_RESURRECT_TTL: ${KONG_DB_RESURRECT_TTL:-30}

      # Router flavor - 'expressions' is fastest for complex routing
      KONG_ROUTER_FLAVOR: ${KONG_ROUTER_FLAVOR:-traditional_compatible}

      # ============================================================
      # LOGGING (optimized for production)
      # ============================================================
      # Buffered logging reduces I/O overhead
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      # Log level (warn in production for reduced overhead)
      KONG_LOG_LEVEL: ${KONG_LOG_LEVEL:-warn}

      # ============================================================
      # LISTENERS
      # ============================================================
      # Admin API - INTERNAL NETWORK ONLY (not exposed to host)
      KONG_ADMIN_LISTEN: 0.0.0.0:8001 reuseport backlog=16384

      # Proxy - PUBLIC with performance flags
      # reuseport: Distribute connections across workers (kernel load balancing)
      # backlog: Increase connection queue for burst handling
      # deferred: Accept connections only when data is ready (reduces context switches)
      KONG_PROXY_LISTEN: "0.0.0.0:8000 reuseport backlog=16384 deferred, 0.0.0.0:8443 ssl http2 reuseport backlog=16384 deferred"

      # Enable HTTP/2 on admin for efficient management
      KONG_ADMIN_GUI_LISTEN: "off"

      # ============================================================
      # PLUGINS
      # ============================================================
      # Enable only needed plugins (reduces memory and CPU overhead)
      KONG_PLUGINS: ${KONG_PLUGINS:-bundled}
      # Plugin server (for custom plugins via gRPC - optional)
      # KONG_PLUGINSERVER_NAMES: ""

      # ============================================================
      # REAL IP HANDLING
      # ============================================================
      KONG_TRUSTED_IPS: 0.0.0.0/0,::/0
      KONG_REAL_IP_HEADER: X-Forwarded-For
      KONG_REAL_IP_RECURSIVE: "on"

      # ============================================================
      # MISC PERFORMANCE
      # ============================================================
      # Shared dictionaries for Lua caching
      KONG_NGINX_HTTP_LUA_SHARED_DICT: "prometheus_metrics 16m, kong_locks 16m, kong_healthchecks 10m, kong_rate_limiting_counters 12m, kong_db_cache ${KONG_DB_CACHE_SIZE:-128m}, kong_db_cache_miss 12m"

      # Disable unnecessary features
      KONG_ANONYMOUS_REPORTS: "off"
      KONG_VITALS: ${KONG_VITALS:-off}

    ports:
      # Proxy ports - PUBLIC (external API traffic)
      - "${KONG_PROXY_HTTP_PORT:-8000}:8000"
      - "${KONG_PROXY_HTTPS_PORT:-8443}:8443"
      # NOTE: Admin API (8001) is NOT exposed to host - internal network only
    networks:
      - marchproxy-internal   # Admin API accessible here
      - marchproxy-external   # Proxy accessible here
    # Resource limits for predictable performance
    deploy:
      resources:
        limits:
          cpus: "${KONG_CPU_LIMIT:-0}"
          memory: "${KONG_MEMORY_LIMIT:-0}"
        reservations:
          cpus: "${KONG_CPU_RESERVATION:-0.5}"
          memory: "${KONG_MEMORY_RESERVATION:-256M}"
    # Increase file descriptor limits
    ulimits:
      nofile:
        soft: 1048576
        hard: 1048576
      nproc:
        soft: 65535
        hard: 65535
    # System tuning via sysctls
    sysctls:
      net.core.somaxconn: 65535
      net.ipv4.tcp_max_syn_backlog: 65535
      net.ipv4.ip_local_port_range: "1024 65535"
      net.ipv4.tcp_tw_reuse: 1
      net.ipv4.tcp_fin_timeout: 15
      net.core.netdev_max_backlog: 65535
      net.ipv4.tcp_keepalive_time: 300
      net.ipv4.tcp_keepalive_intvl: 30
      net.ipv4.tcp_keepalive_probes: 3
      net.ipv4.tcp_syncookies: 1
      net.ipv4.tcp_max_tw_buckets: 1440000
      net.core.rmem_max: 16777216
      net.core.wmem_max: 16777216
      net.ipv4.tcp_rmem: "4096 87380 16777216"
      net.ipv4.tcp_wmem: "4096 65536 16777216"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 10s
      timeout: 5s
      retries: 5
    labels:
      - "service=marchproxy-kong"
      - "component=api-gateway"
      - "layer=apilb"
      - "performance=optimized"

  # ============================================================================
  # MarchProxy Core Services
  # ============================================================================

  # API Server (FastAPI) - Management & xDS Control Plane
  api-server:
    build:
      context: ./api-server
      dockerfile: Dockerfile
    container_name: marchproxy-api-server
    environment:
      # Database
      - DATABASE_URL=postgresql+asyncpg://marchproxy:${POSTGRES_PASSWORD:-marchproxy123}@postgres:5432/marchproxy
      - REDIS_URL=redis://:${REDIS_PASSWORD:-redis123}@redis:6379/0

      # Application
      - SECRET_KEY=${SECRET_KEY:-your-secret-key-change-this}
      - DEBUG=${DEBUG:-false}
      - LOG_LEVEL=${LOG_LEVEL:-info}

      # xDS Control Plane
      - XDS_GRPC_PORT=18000
      - XDS_GRPC_BIND=0.0.0.0:18000

      # License
      - LICENSE_KEY=${LICENSE_KEY:-}
      - LICENSE_SERVER_URL=${LICENSE_SERVER_URL:-https://license.penguintech.io}

      # CORS
      - CORS_ORIGINS=${CORS_ORIGINS:-http://localhost:3000,http://webui:3000}

      # Observability
      - JAEGER_ENABLED=${JAEGER_ENABLED:-true}
      - JAEGER_HOST=jaeger
      - JAEGER_PORT=6831
    ports:
      - "8000:8000"   # REST API
      - "18000:18000" # xDS gRPC
    networks:
      - marchproxy-internal
      - marchproxy-external
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - "service=marchproxy-api-server"
      - "component=api"

  # Web UI (React + Vite)
  webui:
    build:
      context: ./webui
      dockerfile: Dockerfile
    container_name: marchproxy-webui
    environment:
      - VITE_API_URL=http://api-server:8000
      - VITE_KONG_ADMIN_URL=http://kong:8001
      - VITE_JAEGER_URL=http://jaeger:16686
      - NODE_ENV=production
      - HOST=0.0.0.0
      - PORT=3000
    ports:
      - "3000:3000"
    networks:
      - marchproxy-internal
      - marchproxy-external
    depends_on:
      - api-server
      - kong
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - "service=marchproxy-webui"
      - "component=ui"

  # ============================================================================
  # MarchProxy Unified NLB Architecture
  # ============================================================================

  # NLB Container - Single Entry Point (L3/L4)
  proxy-nlb:
    build:
      context: ./proxy-nlb
      dockerfile: Dockerfile
    container_name: marchproxy-proxy-nlb
    environment:
      # API Server connection
      - API_SERVER_URL=http://api-server:8000
      - XDS_SERVER=api-server:18000
      - CLUSTER_API_KEY=${CLUSTER_API_KEY:-default-api-key}

      # Proxy configuration
      - PROXY_NAME=${PROXY_NLB_NAME:-proxy-nlb-1}
      - LISTEN_PORT=${NLB_PORT:-7000}
      - ADMIN_PORT=7001
      - LOG_LEVEL=${LOG_LEVEL:-info}

      # Module gRPC endpoints (internal network)
      - ALB_GRPC=proxy-alb:50051
      - DBLB_GRPC=proxy-dblb:50052
      - AILB_GRPC=proxy-ailb:50053
      - RTMP_GRPC=proxy-rtmp:50054

      # Network acceleration
      - ENABLE_EBPF=${ENABLE_EBPF:-true}
      - ENABLE_XDP=${ENABLE_XDP:-false}
      - ENABLE_AF_XDP=${ENABLE_AF_XDP:-false}

      # Rate limiting
      - RATE_LIMIT_ENABLED=${RATE_LIMIT_ENABLED:-true}
      - RATE_LIMIT_RPS=${RATE_LIMIT_RPS:-10000}

      # Auto-scaling
      - AUTO_SCALING_ENABLED=${AUTO_SCALING_ENABLED:-false}
      - SCALE_MIN_INSTANCES=${SCALE_MIN_INSTANCES:-1}
      - SCALE_MAX_INSTANCES=${SCALE_MAX_INSTANCES:-10}

      # Blue/Green deployments
      - BLUE_GREEN_ENABLED=${BLUE_GREEN_ENABLED:-false}

      # Observability
      - JAEGER_ENABLED=${JAEGER_ENABLED:-true}
      - JAEGER_HOST=jaeger
      - JAEGER_PORT=6831
    ports:
      - "${NLB_PORT:-7000}:${NLB_PORT:-7000}"  # Main entry point
      - "7001:7001"  # Admin/Metrics
    networks:
      - marchproxy-internal
      - marchproxy-external
    cap_add:
      - NET_ADMIN
      - SYS_RESOURCE
    depends_on:
      - api-server
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7001/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - "service=marchproxy-proxy-nlb"
      - "component=proxy"
      - "layer=network"

  # ALB Container - Application Load Balancer (L7 Envoy)
  proxy-alb:
    build:
      context: ./proxy-l7
      dockerfile: Dockerfile
    container_name: marchproxy-proxy-alb
    environment:
      # xDS control plane
      - XDS_SERVER=api-server:18000
      - CLUSTER_API_KEY=${CLUSTER_API_KEY:-default-api-key}

      # Envoy configuration
      - ENVOY_LOG_LEVEL=${ENVOY_LOG_LEVEL:-info}
      - NUM_WORKERS=${NUM_WORKERS:-4}

      # gRPC server (ModuleService)
      - GRPC_PORT=50051
      - GRPC_BIND=0.0.0.0:50051

      # Module configuration
      - MODULE_TYPE=alb
      - MODULE_NAME=${ALB_NAME:-proxy-alb-1}

      # Rate limiting per route
      - RATE_LIMIT_ENABLED=${ALB_RATE_LIMIT:-true}

      # Observability
      - JAEGER_ENABLED=${JAEGER_ENABLED:-true}
      - JAEGER_HOST=jaeger
      - JAEGER_PORT=6831
    ports:
      - "80:80"       # HTTP
      - "443:443"     # HTTPS
      - "8080:8080"   # HTTP/2
      - "9901:9901"   # Envoy admin
      - "50051:50051" # gRPC ModuleService
    networks:
      - marchproxy-internal
    cap_add:
      - NET_ADMIN
    depends_on:
      - api-server
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9901/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - "service=marchproxy-proxy-alb"
      - "component=proxy"
      - "layer=application"
      - "module=alb"

  # DBLB Container - Database Load Balancer (ArticDBM)
  proxy-dblb:
    build:
      context: ./proxy-dblb
      dockerfile: Dockerfile
    container_name: marchproxy-proxy-dblb
    profiles:
      - full
      - dblb
    environment:
      # API Server connection
      - API_SERVER_URL=http://api-server:8000
      - CLUSTER_API_KEY=${CLUSTER_API_KEY:-default-api-key}

      # gRPC server (ModuleService)
      - GRPC_PORT=50052
      - GRPC_BIND=0.0.0.0:50052

      # Module configuration
      - MODULE_TYPE=dblb
      - MODULE_NAME=${DBLB_NAME:-proxy-dblb-1}
      - ADMIN_PORT=7002
      - LOG_LEVEL=${LOG_LEVEL:-info}

      # Database proxy ports
      - MYSQL_PORT=3306
      - POSTGRESQL_PORT=5432
      - MONGODB_PORT=27017
      - REDIS_PORT=6380
      - MSSQL_PORT=1433

      # Connection pooling
      - POOL_SIZE=${DBLB_POOL_SIZE:-100}
      - POOL_MAX_OVERFLOW=${DBLB_POOL_MAX:-200}

      # Security
      - SQL_INJECTION_CHECK=${SQL_INJECTION_CHECK:-true}

      # Rate limiting per database route
      - RATE_LIMIT_ENABLED=${DBLB_RATE_LIMIT:-true}

      # Observability
      - JAEGER_ENABLED=${JAEGER_ENABLED:-true}
      - JAEGER_HOST=jaeger
      - JAEGER_PORT=6831
    ports:
      - "3306:3306"   # MySQL
      - "5433:5432"   # PostgreSQL (offset to avoid conflict)
      - "27017:27017" # MongoDB
      - "6380:6380"   # Redis (offset)
      - "1433:1433"   # MSSQL
      - "7002:7002"   # Admin/Metrics
      - "50052:50052" # gRPC ModuleService
    networks:
      - marchproxy-internal
    depends_on:
      - api-server
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7002/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - "service=marchproxy-proxy-dblb"
      - "component=proxy"
      - "layer=database"
      - "module=dblb"

  # AILB Container - AI/LLM Load Balancer (WaddleAI)
  proxy-ailb:
    build:
      context: ./proxy-ailb
      dockerfile: Dockerfile
    container_name: marchproxy-proxy-ailb
    profiles:
      - full
      - ailb
    environment:
      # API Server connection
      - API_SERVER_URL=http://api-server:8000
      - CLUSTER_API_KEY=${CLUSTER_API_KEY:-default-api-key}

      # gRPC server (ModuleService)
      - GRPC_PORT=50053
      - GRPC_BIND=0.0.0.0:50053

      # Module configuration
      - MODULE_TYPE=ailb
      - MODULE_NAME=${AILB_NAME:-proxy-ailb-1}
      - HTTP_PORT=7003
      - ADMIN_PORT=7004
      - LOG_LEVEL=${LOG_LEVEL:-info}

      # AI Provider API keys (from environment)
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - OLLAMA_URL=${OLLAMA_URL:-http://ollama:11434}

      # Conversation memory
      - REDIS_URL=redis://:${REDIS_PASSWORD:-redis123}@redis:6379/1

      # RAG configuration
      - RAG_ENABLED=${RAG_ENABLED:-false}
      - RAG_VECTOR_STORE=${RAG_VECTOR_STORE:-faiss}

      # Rate limiting per AI provider route
      - RATE_LIMIT_ENABLED=${AILB_RATE_LIMIT:-true}
      - RATE_LIMIT_RPM=${AILB_RATE_LIMIT_RPM:-60}

      # Observability
      - JAEGER_ENABLED=${JAEGER_ENABLED:-true}
      - JAEGER_HOST=jaeger
      - JAEGER_PORT=6831
    ports:
      - "7003:7003"   # HTTP API
      - "7004:7004"   # Admin/Metrics
      - "50053:50053" # gRPC ModuleService
    networks:
      - marchproxy-internal
    depends_on:
      - api-server
      - redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7004/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - "service=marchproxy-proxy-ailb"
      - "component=proxy"
      - "layer=ai"
      - "module=ailb"

  # RTMP Container - Video Transcoding (CPU variant)
  proxy-rtmp:
    build:
      context: ./proxy-rtmp
      dockerfile: Dockerfile
      target: cpu
    container_name: marchproxy-proxy-rtmp
    profiles:
      - full
      - rtmp
    environment:
      # API Server connection
      - API_SERVER_URL=http://api-server:8000
      - CLUSTER_API_KEY=${CLUSTER_API_KEY:-default-api-key}

      # gRPC server (ModuleService)
      - GRPC_PORT=50054
      - GRPC_BIND=0.0.0.0:50054

      # Module configuration
      - MODULE_TYPE=rtmp
      - MODULE_NAME=${RTMP_NAME:-proxy-rtmp-1}
      - RTMP_PORT=1935
      - ADMIN_PORT=7005
      - LOG_LEVEL=${LOG_LEVEL:-info}

      # FFmpeg configuration
      - FFMPEG_THREADS=${FFMPEG_THREADS:-4}
      - TRANSCODE_PRESET=${TRANSCODE_PRESET:-medium}
      - VIDEO_CODEC=${VIDEO_CODEC:-x264}

      # Output formats
      - HLS_ENABLED=${HLS_ENABLED:-true}
      - HLS_SEGMENT_DURATION=${HLS_SEGMENT_DURATION:-6}
      - DASH_ENABLED=${DASH_ENABLED:-false}

      # Rate limiting per stream
      - RATE_LIMIT_ENABLED=${RTMP_RATE_LIMIT:-true}

      # Observability
      - JAEGER_ENABLED=${JAEGER_ENABLED:-true}
      - JAEGER_HOST=jaeger
      - JAEGER_PORT=6831
    ports:
      - "1935:1935"   # RTMP
      - "8081:8081"   # HLS/DASH HTTP
      - "7005:7005"   # Admin/Metrics
      - "50054:50054" # gRPC ModuleService
    volumes:
      - rtmp_streams:/streams
    networks:
      - marchproxy-internal
    depends_on:
      - api-server
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7005/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - "service=marchproxy-proxy-rtmp"
      - "component=proxy"
      - "layer=video"
      - "module=rtmp"
      - "variant=cpu"

  # ============================================================================
  # Observability Stack
  # ============================================================================

  # Jaeger for distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: marchproxy-jaeger
    environment:
      - COLLECTOR_ZIPKIN_HTTP_PORT=9411
      - MEMORY_MAX_TRACES=10000
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686"  # Jaeger UI
      - "14268:14268"
      - "14250:14250"
      - "9411:9411"
    networks:
      - marchproxy-internal
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:16686"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      - "service=marchproxy-jaeger"
      - "component=observability"

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: marchproxy-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - marchproxy-internal
    restart: unless-stopped

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: marchproxy-grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin123}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    ports:
      - "3001:3000"  # Offset to avoid conflict with webui
    networks:
      - marchproxy-internal
    depends_on:
      - prometheus
    restart: unless-stopped

# ============================================================================
# Networks
# ============================================================================
networks:
  marchproxy-internal:
    driver: bridge
    internal: false  # Needs external access for license validation
    ipam:
      config:
        - subnet: 172.20.0.0/16
    labels:
      - "network=marchproxy-internal"
      - "purpose=grpc-communication"

  marchproxy-external:
    driver: bridge
    ipam:
      config:
        - subnet: 172.21.0.0/16
    labels:
      - "network=marchproxy-external"
      - "purpose=public-access"

# ============================================================================
# Volumes
# ============================================================================
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  kong_db_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  rtmp_streams:
    driver: local
